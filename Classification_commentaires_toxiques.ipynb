{"cells":[{"cell_type":"markdown","metadata":{"id":"_lyJzHuKRNWX"},"source":["# Importation des packages"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"MUj96QiIQsJ_"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","#import matplotlib.pyplot as plt\n","#import tensorflow as tf\n","\n","import NLTK\n","import re"]},{"cell_type":"markdown","metadata":{"id":"xZLpUMItRWc0"},"source":["# Importation des données"]},{"cell_type":"markdown","metadata":{"id":"cbE3MzVKRaV2"},"source":["Ajoutez un raccourci de ce dossier à votre google drive :\n","\n","https://drive.google.com/drive/folders/1mx-CAzT10YKrmxHfYDP_1Oef7PVGUr7s?usp=sharing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28361,"status":"ok","timestamp":1645597882479,"user":{"displayName":"Gautherot Morgan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07974205866322024288"},"user_tz":-60},"id":"4FktfCVaRVrs","outputId":"5b61276d-d759-4384-d8bb-08ed0b57ae69"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":2823,"status":"ok","timestamp":1645598103254,"user":{"displayName":"Gautherot Morgan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07974205866322024288"},"user_tz":-60},"id":"qky64Lq8Rocy","outputId":"3f57ca8f-59ae-4e38-e35d-a040b2e6a944"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>comment_text</th>\n","      <th>toxic</th>\n","      <th>severe_toxic</th>\n","      <th>obscene</th>\n","      <th>threat</th>\n","      <th>insult</th>\n","      <th>identity_hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000997932d777bf</td>\n","      <td>Explanation\\nWhy the edits made under my usern...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000103f0d9cfb60f</td>\n","      <td>D'aww! He matches this background colour I'm s...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>000113f07ec002fd</td>\n","      <td>Hey man, I'm really not trying to edit war. It...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0001b41b1c6bb37e</td>\n","      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0001d958c54c6e35</td>\n","      <td>You, sir, are my hero. Any chance you remember...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 id                                       comment_text  toxic  \\\n","0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n","1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n","2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n","3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n","4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n","\n","   severe_toxic  obscene  threat  insult  identity_hate  \n","0             0        0       0       0              0  \n","1             0        0       0       0              0  \n","2             0        0       0       0              0  \n","3             0        0       0       0              0  \n","4             0        0       0       0              0  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["data = pd.read_csv('./data_classification_commentaires_toxiques/train.csv')\n","data.head()"]},{"cell_type":"markdown","metadata":{"id":"-kUWzBzISpsK"},"source":["# Etude du jeu de données"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"CAexGL7jS-VF"},"outputs":[{"name":"stdout","output_type":"stream","text":["toxic: 15294\n","severe_toxic: 1595\n","obscene: 8449\n","threat: 478\n","insult: 7877\n","identity_hate: 1405\n"]},{"data":{"text/plain":["isToxic\n","0    143346\n","1     16225\n","Name: count, dtype: int64"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# check how much comment text is set as toxic, severe_toxic, obscene, threat, insult, identity_hate\n","i=0\n","for label in ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']:\n","    print(f'{label}: {data[label].value_counts()[1]}')\n","\n","# Create a label isToxic where isToxic = 1 if any of the toxic, severe_toxic, obscene, threat, insult, identity_hate is 1\n","data['isToxic'] = data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].max(axis=1)\n","data['isToxic'].value_counts()\n"]},{"cell_type":"markdown","metadata":{"id":"YIzpSrAjSsAM"},"source":["# Préparation des données"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1WMk85t8S_zX"},"outputs":[],"source":["# Create a tokenizer using the TweetTokenizer class from nltk.tokenize module\n","tokenizer = nltk.tokenize.TweetTokenizer(strip_handles=True)\n","# Download the stopwords from the nltk.corpus module\n","nltk.download('stopwords')\n","# Get the list of stopwords for the English language  \n","stop_words = nltk.corpus.stopwords.words('english')\n","# Create an empty list to store the corpus\n","corpus = []"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def clean(tweet): \n","            \n","    # Contractions\n","    tweet = re.sub(r\"he's\", \"he is\", tweet)\n","    tweet = re.sub(r\"there's\", \"there is\", tweet)\n","    tweet = re.sub(r\"We're\", \"We are\", tweet)\n","    tweet = re.sub(r\"That's\", \"That is\", tweet)\n","    tweet = re.sub(r\"won't\", \"will not\", tweet)\n","    tweet = re.sub(r\"they're\", \"they are\", tweet)\n","    tweet = re.sub(r\"Can't\", \"Cannot\", tweet)\n","    tweet = re.sub(r\"wasn't\", \"was not\", tweet)\n","    tweet = re.sub(r\"don\\x89Ûªt\", \"do not\", tweet)\n","    tweet = re.sub(r\"aren't\", \"are not\", tweet)\n","    tweet = re.sub(r\"isn't\", \"is not\", tweet)\n","    tweet = re.sub(r\"What's\", \"What is\", tweet)\n","    tweet = re.sub(r\"haven't\", \"have not\", tweet)\n","    tweet = re.sub(r\"hasn't\", \"has not\", tweet)\n","    tweet = re.sub(r\"There's\", \"There is\", tweet)\n","    tweet = re.sub(r\"He's\", \"He is\", tweet)\n","    tweet = re.sub(r\"It's\", \"It is\", tweet)\n","    tweet = re.sub(r\"You're\", \"You are\", tweet)\n","    tweet = re.sub(r\"I'M\", \"I am\", tweet)\n","    tweet = re.sub(r\"shouldn't\", \"should not\", tweet)\n","    tweet = re.sub(r\"wouldn't\", \"would not\", tweet)\n","    tweet = re.sub(r\"i'm\", \"I am\", tweet)\n","    tweet = re.sub(r\"I\\x89Ûªm\", \"I am\", tweet)\n","    tweet = re.sub(r\"I'm\", \"I am\", tweet)\n","    tweet = re.sub(r\"Isn't\", \"is not\", tweet)\n","    tweet = re.sub(r\"Here's\", \"Here is\", tweet)\n","    tweet = re.sub(r\"you've\", \"you have\", tweet)\n","    tweet = re.sub(r\"you\\x89Ûªve\", \"you have\", tweet)\n","    tweet = re.sub(r\"we're\", \"we are\", tweet)\n","    tweet = re.sub(r\"what's\", \"what is\", tweet)\n","    tweet = re.sub(r\"couldn't\", \"could not\", tweet)\n","    tweet = re.sub(r\"we've\", \"we have\", tweet)\n","    tweet = re.sub(r\"it\\x89Ûªs\", \"it is\", tweet)\n","    tweet = re.sub(r\"doesn\\x89Ûªt\", \"does not\", tweet)\n","    tweet = re.sub(r\"It\\x89Ûªs\", \"It is\", tweet)\n","    tweet = re.sub(r\"Here\\x89Ûªs\", \"Here is\", tweet)\n","    tweet = re.sub(r\"who's\", \"who is\", tweet)\n","    tweet = re.sub(r\"I\\x89Ûªve\", \"I have\", tweet)\n","    tweet = re.sub(r\"y'all\", \"you all\", tweet)\n","    tweet = re.sub(r\"can\\x89Ûªt\", \"cannot\", tweet)\n","    tweet = re.sub(r\"would've\", \"would have\", tweet)\n","    tweet = re.sub(r\"it'll\", \"it will\", tweet)\n","    tweet = re.sub(r\"we'll\", \"we will\", tweet)\n","    tweet = re.sub(r\"wouldn\\x89Ûªt\", \"would not\", tweet)\n","    tweet = re.sub(r\"We've\", \"We have\", tweet)\n","    tweet = re.sub(r\"he'll\", \"he will\", tweet)\n","    tweet = re.sub(r\"Y'all\", \"You all\", tweet)\n","    tweet = re.sub(r\"Weren't\", \"Were not\", tweet)\n","    tweet = re.sub(r\"Didn't\", \"Did not\", tweet)\n","    tweet = re.sub(r\"they'll\", \"they will\", tweet)\n","    tweet = re.sub(r\"they'd\", \"they would\", tweet)\n","    tweet = re.sub(r\"DON'T\", \"DO NOT\", tweet)\n","    tweet = re.sub(r\"That\\x89Ûªs\", \"That is\", tweet)\n","    tweet = re.sub(r\"they've\", \"they have\", tweet)\n","    tweet = re.sub(r\"i'd\", \"I would\", tweet)\n","    tweet = re.sub(r\"should've\", \"should have\", tweet)\n","    tweet = re.sub(r\"You\\x89Ûªre\", \"You are\", tweet)\n","    tweet = re.sub(r\"where's\", \"where is\", tweet)\n","    tweet = re.sub(r\"Don\\x89Ûªt\", \"Do not\", tweet)\n","    tweet = re.sub(r\"we'd\", \"we would\", tweet)\n","    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n","    tweet = re.sub(r\"weren't\", \"were not\", tweet)\n","    tweet = re.sub(r\"They're\", \"They are\", tweet)\n","    tweet = re.sub(r\"Can\\x89Ûªt\", \"Cannot\", tweet)\n","    tweet = re.sub(r\"you\\x89Ûªll\", \"you will\", tweet)\n","    tweet = re.sub(r\"I\\x89Ûªd\", \"I would\", tweet)\n","    tweet = re.sub(r\"let's\", \"let us\", tweet)\n","    tweet = re.sub(r\"it's\", \"it is\", tweet)\n","    tweet = re.sub(r\"can't\", \"cannot\", tweet)\n","    tweet = re.sub(r\"don't\", \"do not\", tweet)\n","    tweet = re.sub(r\"you're\", \"you are\", tweet)\n","    tweet = re.sub(r\"i've\", \"I have\", tweet)\n","    tweet = re.sub(r\"that's\", \"that is\", tweet)\n","    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n","    tweet = re.sub(r\"doesn't\", \"does not\", tweet)\n","    tweet = re.sub(r\"i'd\", \"I would\", tweet)\n","    tweet = re.sub(r\"didn't\", \"did not\", tweet)\n","    tweet = re.sub(r\"ain't\", \"am not\", tweet)\n","    tweet = re.sub(r\"you'll\", \"you will\", tweet)\n","    tweet = re.sub(r\"I've\", \"I have\", tweet)\n","    tweet = re.sub(r\"Don't\", \"do not\", tweet)\n","    tweet = re.sub(r\"I'll\", \"I will\", tweet)\n","    tweet = re.sub(r\"I'd\", \"I would\", tweet)\n","    tweet = re.sub(r\"Let's\", \"Let us\", tweet)\n","    tweet = re.sub(r\"you'd\", \"You would\", tweet)\n","    tweet = re.sub(r\"It's\", \"It is\", tweet)\n","    tweet = re.sub(r\"Ain't\", \"am not\", tweet)\n","    tweet = re.sub(r\"Haven't\", \"Have not\", tweet)\n","    tweet = re.sub(r\"Could've\", \"Could have\", tweet)\n","    tweet = re.sub(r\"youve\", \"you have\", tweet)  \n","    tweet = re.sub(r\"donå«t\", \"do not\", tweet)  \n","    \n","    tweet = re.sub(r\"some1\", \"someone\", tweet)\n","    tweet = re.sub(r\"yrs\", \"years\", tweet)\n","    tweet = re.sub(r\"hrs\", \"hours\", tweet)\n","    tweet = re.sub(r\"2morow|2moro\", \"tomorrow\", tweet)\n","    tweet = re.sub(r\"2day\", \"today\", tweet)\n","    tweet = re.sub(r\"4got|4gotten\", \"forget\", tweet)\n","    tweet = re.sub(r\"b-day|bday\", \"b-day\", tweet)\n","    tweet = re.sub(r\"mother's\", \"mother\", tweet)\n","    tweet = re.sub(r\"mom's\", \"mom\", tweet)\n","    tweet = re.sub(r\"dad's\", \"dad\", tweet)\n","    tweet = re.sub(r\"hahah|hahaha|hahahaha\", \"haha\", tweet)\n","    tweet = re.sub(r\"lmao|lolz|rofl\", \"lol\", tweet)\n","    tweet = re.sub(r\"thanx|thnx\", \"thanks\", tweet)\n","    tweet = re.sub(r\"goood\", \"good\", tweet)\n","    tweet = re.sub(r\"some1\", \"someone\", tweet)\n","    tweet = re.sub(r\"some1\", \"someone\", tweet)\n","    # Character entity references\n","    tweet = re.sub(r\">\", \">\", tweet)\n","    tweet = re.sub(r\"<\", \"<\", tweet)\n","    tweet = re.sub(r\"&\", \"&\", tweet)\n","    # Typos, slang and informal abbreviations\n","    tweet = re.sub(r\"w/e\", \"whatever\", tweet)\n","    tweet = re.sub(r\"w/\", \"with\", tweet)\n","    tweet = re.sub(r\"<3\", \"love\", tweet)\n","    # Urls\n","    tweet = re.sub(r\"http\\S+\", \"\", tweet)\n","    # Numbers\n","    tweet = re.sub(r'[0-9]', '', tweet)\n","    # Eliminating the mentions\n","    tweet = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", tweet)\n","    # Remove punctuation and special chars (keep '!')\n","    for p in string.punctuation.replace('!', ''):\n","        tweet = tweet.replace(p, '')\n","        \n","    # ... and ..\n","    tweet = tweet.replace('...', ' ... ')\n","    if '...' not in tweet:\n","        tweet = tweet.replace('..', ' ... ')\n","        \n","    # Tokenize\n","    tweet_words = tokenizer.tokenize(tweet)\n","    \n","    # Eliminating the word if its length is less than 3\n","    tweet = [w for w in tweet_words if len(w)>2]\n","    \n","    # remove stopwords\n","    tweet = [w.lower() for w in tweet if not w in stop_words]  \n","    \n","    corpus.append(tweet)\n","    \n","    # join back\n","    tweet = ' '.join(tweet)\n","        \n","        \n","    return tweet"]},{"cell_type":"markdown","metadata":{"id":"LxNIQgESTCmE"},"source":["# Entraînement du modèle baseline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YgkPpzIzSQUi"},"outputs":[],"source":["# Your Code"]},{"cell_type":"markdown","metadata":{"id":"2a8IWbTFTHXh"},"source":["# Itération de la modélisation "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rVR0eCkoTQSI"},"outputs":[],"source":["# Your Code "]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMCSqKm9bskmrKsd3y9MwY2","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":0}
